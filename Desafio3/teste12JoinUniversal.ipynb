{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:195: DtypeWarning: Columns (12,16,26,31,33,34,37,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Eduarda\\AppData\\Local\\Temp\\ipykernel_25484\\1114389315.py\", line 95, in perform_join_and_display_ages\n",
      "    show_results_in_table(merged_df)\n",
      "  File \"C:\\Users\\Eduarda\\AppData\\Local\\Temp\\ipykernel_25484\\1114389315.py\", line 29, in show_results_in_table\n",
      "    pt = Table(frame, dataframe=df.compute())  # Usar .compute() para converter o DataFrame Dask em Pandas\n",
      "                                ^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\base.py\", line 310, in compute\n",
      "    (result,) = compute(self, traverse=False, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\base.py\", line 595, in compute\n",
      "    results = schedule(dsk, keys, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\threaded.py\", line 89, in get\n",
      "    results = get_async(\n",
      "              ^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\local.py\", line 511, in get_async\n",
      "    raise_exception(exc, tb)\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\local.py\", line 319, in reraise\n",
      "    raise exc\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\local.py\", line 224, in execute_task\n",
      "    result = _execute_task(task, data)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\core.py\", line 121, in _execute_task\n",
      "    return func(*(_execute_task(a, cache) for a in args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\optimization.py\", line 992, in __call__\n",
      "    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\core.py\", line 151, in get\n",
      "    result = _execute_task(task, cache)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\core.py\", line 121, in _execute_task\n",
      "    return func(*(_execute_task(a, cache) for a in args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\core.py\", line 121, in <genexpr>\n",
      "    return func(*(_execute_task(a, cache) for a in args))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\core.py\", line 115, in _execute_task\n",
      "    return [_execute_task(a, cache) for a in arg]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\core.py\", line 115, in <listcomp>\n",
      "    return [_execute_task(a, cache) for a in arg]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\core.py\", line 121, in _execute_task\n",
      "    return func(*(_execute_task(a, cache) for a in args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py\", line 142, in __call__\n",
      "    df = pandas_read_text(\n",
      "         ^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py\", line 197, in pandas_read_text\n",
      "    coerce_dtypes(df, dtypes)\n",
      "  File \"d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py\", line 298, in coerce_dtypes\n",
      "    raise ValueError(msg)\n",
      "ValueError: Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n",
      "\n",
      "+-----------------------------------+---------+----------+\n",
      "| Column                            | Found   | Expected |\n",
      "+-----------------------------------+---------+----------+\n",
      "| cbo                               | object  | float64  |\n",
      "| codigoContemComunidadeTradicional | object  | int64    |\n",
      "| codigoEstrategiaCovid             | float64 | int64    |\n",
      "| codigoFabricanteTeste4            | object  | float64  |\n",
      "| codigoLocalRealizacaoTestagem     | float64 | int64    |\n",
      "| codigoRecebeuVacina               | object  | float64  |\n",
      "| codigoResultadoTeste4             | object  | float64  |\n",
      "| condicoes                         | object  | float64  |\n",
      "| dataColetaTeste3                  | object  | float64  |\n",
      "| dataColetaTeste4                  | object  | float64  |\n",
      "| municipioIBGE                     | object  | int64    |\n",
      "| municipioNotificacaoIBGE          | object  | int64    |\n",
      "| outrasCondicoes                   | object  | float64  |\n",
      "| outroBuscaAtivaAssintomatico      | object  | float64  |\n",
      "| outroTriagemPopulacaoEspecifica   | object  | float64  |\n",
      "| totalTestesRealizados             | object  | int64    |\n",
      "+-----------------------------------+---------+----------+\n",
      "\n",
      "The following columns also raised exceptions on conversion:\n",
      "\n",
      "- cbo\n",
      "  ValueError(\"could not convert string to float: '3222 - Técnicos e auxiliares de enfermagem'\")\n",
      "- codigoContemComunidadeTradicional\n",
      "  ValueError('cannot convert float NaN to integer')\n",
      "- codigoFabricanteTeste4\n",
      "  ValueError(\"could not convert string to float: '2022-11-11'\")\n",
      "- codigoRecebeuVacina\n",
      "  ValueError(\"could not convert string to float: 'PFIZER'\")\n",
      "- codigoResultadoTeste4\n",
      "  ValueError(\"could not convert string to float: '2022-04-13'\")\n",
      "- condicoes\n",
      "  ValueError(\"could not convert string to float: 'Doenças cardíacas crônicas, Doenças respiratórias crônicas descompensadas'\")\n",
      "- dataColetaTeste3\n",
      "  ValueError(\"could not convert string to float: '2022-08-15'\")\n",
      "- dataColetaTeste4\n",
      "  ValueError(\"could not convert string to float: '2022-03-18'\")\n",
      "- municipioIBGE\n",
      "  ValueError('cannot convert float NaN to integer')\n",
      "- municipioNotificacaoIBGE\n",
      "  ValueError('cannot convert float NaN to integer')\n",
      "- outrasCondicoes\n",
      "  ValueError(\"could not convert string to float: 'EPILEPSIA'\")\n",
      "- outroBuscaAtivaAssintomatico\n",
      "  ValueError(\"could not convert string to float: 'SEM INFORMAÇÃO'\")\n",
      "- outroTriagemPopulacaoEspecifica\n",
      "  ValueError(\"could not convert string to float: 'PARTIU TESTAGEM'\")\n",
      "- totalTestesRealizados\n",
      "  ValueError(\"invalid literal for int() with base 10: '2022-11-09'\")\n",
      "\n",
      "Usually this is due to dask's dtype inference failing, and\n",
      "*may* be fixed by specifying dtypes manually by adding:\n",
      "\n",
      "dtype={'cbo': 'object',\n",
      "       'codigoContemComunidadeTradicional': 'object',\n",
      "       'codigoEstrategiaCovid': 'float64',\n",
      "       'codigoFabricanteTeste4': 'object',\n",
      "       'codigoLocalRealizacaoTestagem': 'float64',\n",
      "       'codigoRecebeuVacina': 'object',\n",
      "       'codigoResultadoTeste4': 'object',\n",
      "       'condicoes': 'object',\n",
      "       'dataColetaTeste3': 'object',\n",
      "       'dataColetaTeste4': 'object',\n",
      "       'municipioIBGE': 'object',\n",
      "       'municipioNotificacaoIBGE': 'object',\n",
      "       'outrasCondicoes': 'object',\n",
      "       'outroBuscaAtivaAssintomatico': 'object',\n",
      "       'outroTriagemPopulacaoEspecifica': 'object',\n",
      "       'totalTestesRealizados': 'object'}\n",
      "\n",
      "to the call to `read_csv`/`read_table`.\n",
      "d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:195: DtypeWarning: Columns (12,26,31,33,34,37,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n",
      "d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:195: DtypeWarning: Columns (12,31,34,37,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Eduarda\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:195: DtypeWarning: Columns (12,26,31,34,37,58,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import zipfile\n",
    "import os\n",
    "import requests\n",
    "import dask.dataframe as dd\n",
    "import io\n",
    "import codecs\n",
    "import dbfread  # Será necessário instalar essa biblioteca via pip (pip install dbfread)\n",
    "import tempfile\n",
    "from pandastable import Table, TableModel\n",
    "\n",
    "# Função para remover acentos e caracteres especiais\n",
    "def remove_special_characters(text):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))\n",
    "\n",
    "# Função para mostrar os resultados em uma tabela\n",
    "def show_results_in_table(df):\n",
    "    # Criar uma nova janela para exibir a tabela\n",
    "    table_window = tk.Toplevel(root)\n",
    "    table_window.title(\"Resultado do JOIN\")\n",
    "\n",
    "    # Criar o widget da tabela\n",
    "    frame = ttk.Frame(table_window)\n",
    "    frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    pt = Table(frame, dataframe=df.compute())  # Usar .compute() para converter o DataFrame Dask em Pandas\n",
    "    pt.show()\n",
    "\n",
    "# Função para realizar o JOIN entre os DataFrames\n",
    "def perform_join_and_display_ages():\n",
    "    # Solicitar a URL do arquivo CSV da Bahia\n",
    "    url = csv_url_entry.get()\n",
    "    if not url:\n",
    "        result_label.config(text=\"URL da Bahia não fornecida.\")\n",
    "        return\n",
    "\n",
    "    # Solicitar a URL do arquivo ZIP\n",
    "    zip_file_url = zip_url_entry.get()\n",
    "    if not zip_file_url:\n",
    "        result_label.config(text=\"URL do arquivo ZIP do Rio de Janeiro não fornecida.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Ler o arquivo CSV\n",
    "        #df_url = dd.read_csv(url, delimiter=determinar_delimitador(url))\n",
    "        df_url = dd.read_csv(url, delimiter=determinar_delimitador(url), low_memory=False)\n",
    "    except Exception as e:\n",
    "        error_message = f\"Erro ao ler o arquivo CSV. Detalhes do erro: {str(e)}\"\n",
    "        result_label.config(text=error_message)\n",
    "        print(error_message)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Download do arquivo ZIP\n",
    "        r = requests.get(zip_file_url, stream=True)\n",
    "        temp_zip_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "\n",
    "        # Escrever o conteúdo do arquivo ZIP temporário\n",
    "        with open(temp_zip_file.name, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "        # Extrair o arquivo ZIP\n",
    "        with zipfile.ZipFile(temp_zip_file.name, 'r') as z:\n",
    "            dbf_files = [file for file in z.namelist() if file.endswith('.dbf')]\n",
    "            if not dbf_files:\n",
    "                raise ValueError(\"Não foi encontrado nenhum arquivo DBF no arquivo ZIP.\")\n",
    "\n",
    "            # Considerando o primeiro arquivo DBF encontrado no ZIP\n",
    "            z.extract(dbf_files[0])\n",
    "            dbf_file_path = os.path.join(os.getcwd(), dbf_files[0])\n",
    "\n",
    "        # Lendo o arquivo DBF com a especificação de codificação\n",
    "        with open(dbf_file_path, 'rb') as dbf_file:\n",
    "            dbf_content = dbf_file.read()\n",
    "            # Lendo o arquivo DBF sem usar BytesIO\n",
    "            df_dbf = pd.DataFrame(iter(dbfread.DBF(dbf_file_path, encoding='latin1')))\n",
    "\n",
    "            # Convertendo a coluna 'CD_MUN' para int64 no df_dbf\n",
    "            df_dbf['CD_MUN'] = df_dbf['CD_MUN'].astype('int64')\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Erro ao baixar, ler o arquivo ZIP ou realizar JOIN. Detalhes do erro: {str(e)}\"\n",
    "        result_label.config(text=error_message)\n",
    "        print(error_message)\n",
    "        return\n",
    "    \n",
    "    # Realizar o merge usando Dask\n",
    "    join_type = join_type_var.get()  # Tipo de JOIN selecionado (inner, outer, left, right)\n",
    "    merged_df = dd.merge(df_url, df_dbf, left_on='municipioIBGE', right_on='CD_MUN', how=join_type)\n",
    "    \n",
    "    # Mostrar os resultados em uma tabela\n",
    "    show_results_in_table(merged_df)\n",
    "\n",
    "    # Verificar a presença das colunas 'municipioIBGE' e 'CD_MUN' nos DataFrames originais\n",
    "    if 'municipioIBGE' not in df_url.columns or 'CD_MUN' not in df_dbf.columns:\n",
    "        error_message = \"As colunas 'municipioIBGE' e 'CD_MUN' não estão presentes nos DataFrames originais.\"\n",
    "        result_label.config(text=error_message)\n",
    "        print(error_message)\n",
    "        return\n",
    "    \n",
    "    # Realizar o merge usando Dask\n",
    "    join_type = join_type_var.get()  # Tipo de JOIN selecionado (inner, outer, left, right)\n",
    "    merged_df = dd.merge(df_url, df_dbf, left_on='municipioIBGE', right_on='CD_MUN', how=join_type)\n",
    "    \n",
    "    # Exibir a coluna 'AREA_KM2' após o merge se ela existir\n",
    "    if 'AREA_KM2' in merged_df.columns:\n",
    "        result_label.config(text=\"Coluna 'AREA_KM2' após o JOIN:\\n\" + str(merged_df['AREA_KM2']))\n",
    "    else:\n",
    "        result_label.config(text=\"A coluna 'AREA_KM2' não existe no DataFrame resultante.\")\n",
    "\n",
    "# Função para determinar o delimitador do arquivo CSV\n",
    "def determinar_delimitador(url):\n",
    "    r = requests.get(url)\n",
    "    line = r.content.decode().splitlines()[0]\n",
    "    delimiters = [',', ';', '\\t']\n",
    "    for delimiter in delimiters:\n",
    "        if delimiter in line:\n",
    "            return delimiter\n",
    "    return ','  # Delimitador padrão é a vírgula\n",
    "\n",
    "# Configuração da janela principal\n",
    "root = tk.Tk()\n",
    "root.title(\"App Join Dataframes\")\n",
    "\n",
    "# URL csv\n",
    "csv_url_label = ttk.Label(root, text=\"URL do arquivo CSV:\")\n",
    "csv_url_entry = ttk.Entry(root, width=40)\n",
    "\n",
    "# URL do arquivo ZIP\n",
    "zip_url_label = ttk.Label(root, text=\"URL do arquivo ZIP:\")\n",
    "zip_url_entry = ttk.Entry(root, width=40)\n",
    "\n",
    "# Tipo de JOIN\n",
    "join_type_var = tk.StringVar()\n",
    "join_type_label = ttk.Label(root, text=\"Tipo de JOIN:\")\n",
    "join_type_combobox = ttk.Combobox(root, textvariable=join_type_var, values=[\"inner\", \"outer\", \"left\", \"right\"])\n",
    "\n",
    "# Botão para realizar a operação de JOIN\n",
    "join_button = ttk.Button(root, text=\"Carregar\", command=perform_join_and_display_ages)\n",
    "\n",
    "# Rótulo para exibir a coluna 'AREA_KM2' após o merge\n",
    "result_label = ttk.Label(root, text=\"\")\n",
    "\n",
    "# Posicionamento dos widgets\n",
    "csv_url_label.grid(row=0, column=0, sticky=\"w\")\n",
    "csv_url_entry.grid(row=0, column=1, columnspan=2, sticky=\"w\")\n",
    "zip_url_label.grid(row=1, column=0, sticky=\"w\")\n",
    "zip_url_entry.grid(row=1, column=1, columnspan=2, sticky=\"w\")\n",
    "join_type_label.grid(row=2, column=0, sticky=\"w\")\n",
    "join_type_combobox.grid(row=2, column=1, columnspan=2, sticky=\"w\")\n",
    "join_button.grid(row=3, column=0, columnspan=3, pady=10)\n",
    "result_label.grid(row=4, column=0, columnspan=3, pady=10)\n",
    "\n",
    "# Iniciar a interface gráfica\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
